{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Load Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, UNet2DConditionModel, CLIPTextModel\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import t2v_metrics\n",
    "\n",
    "\n",
    "\n",
    "def load_pipeline(unet_ckpt, text_encoder_ckpt, device):\n",
    "    \"\"\"\n",
    "    Load the base Stable Diffusion pipeline on the specified device.\n",
    "    If a checkpoint is provided, replace the UNet.\n",
    "    If a text encoder checkpoint is provided, replace the text encoder.\n",
    "    \"\"\"\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(base_model_name, torch_dtype=torch.float16)\n",
    "    pipe = pipe.to(device)\n",
    "    pipe.safety_checker = None  # disable safety checker if desired\n",
    "    \n",
    "    if unet_ckpt is not None:\n",
    "        unet = UNet2DConditionModel.from_pretrained(\n",
    "            unet_ckpt, subfolder=\"unet\", torch_dtype=torch.float16\n",
    "        ).to(device)\n",
    "        pipe.unet = unet\n",
    "        \n",
    "    if text_encoder_ckpt is not None:\n",
    "        text_encoder = CLIPTextModel.from_pretrained(\n",
    "            text_encoder_ckpt, subfolder=\"text_encoder\", torch_dtype=torch.float16\n",
    "        ).to(device)\n",
    "        pipe.text_encoder = text_encoder\n",
    "        \n",
    "    return pipe\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
