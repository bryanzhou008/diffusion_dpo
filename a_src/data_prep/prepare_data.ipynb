{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep DPO and SFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Parameter Setup\n",
    "\n",
    "# Number of win-lose pairs (for dpo) or number of win examples (for sft) to use per prompt.\n",
    "num_train_per_prompt = 9\n",
    "dialect = \"ine\"\n",
    "method = \"dpo\"   # sft or dpo\n",
    "prompt_stype = \"basic\" # basic or complex\n",
    "\n",
    "\n",
    "exp_name = f\"{dialect}-{method}-{prompt_stype}-2-2-2-{num_train_per_prompt}\"\n",
    "num_processes = 7\n",
    "\n",
    "\n",
    "# Path to the input CSV file (with header: Dialect_Word, SAE_Word, Dialect_Prompt, SAE_Prompt)\n",
    "csv_file = f\"/local1/bryanzhou008/Dialect/multimodal-dialectal-bias/data/text/train_val_test/2-2-2/{prompt_stype}/{dialect}/train.csv\"\n",
    "\n",
    "# Path to the input images folder; inside this folder, there will be subfolders named after each prompt.\n",
    "input_images_folder = f\"/local1/bryanzhou008/Dialect/multimodal-dialectal-bias/data/image/{prompt_stype}/{dialect}/flux.1-dev\"\n",
    "\n",
    "# Output directory for the prepared dataset.\n",
    "output_folder = f\"/local1/bryanzhou008/Dialect/multimodal-dialectal-bias/mitigation/baselines/diffusion_dpo/a_data/{exp_name}\"\n",
    "\n",
    "# The shell script command template for training (you may adjust this command as needed).\n",
    "script_command = \"\"\"#!/bin/bash\n",
    "export MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\n",
    "export DATA_DIR=\"{output_dir}\"\n",
    "\n",
    "accelerate launch --num_processes {num_processes} /local1/bryanzhou008/Dialect/multimodal-dialectal-bias/mitigation/baselines/diffusion_dpo/a_src/train/train.py \\\\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\\\n",
    "  --train_data_dir=$DATA_DIR \\\\\n",
    "  --train_batch_size=1 \\\\\n",
    "  --dataloader_num_workers=16 \\\\\n",
    "  --gradient_accumulation_steps=128 \\\\\n",
    "  --max_train_steps=2000 \\\\\n",
    "  --lr_scheduler=\"constant_with_warmup\" --lr_warmup_steps=500 \\\\\n",
    "  --learning_rate=1e-8 --scale_lr \\\\\n",
    "  --cache_dir=\"/local1/bryanzhou008/Dialect/multimodal-dialectal-bias/mitigation/baselines/diffusion_dpo/temp_cache/\" \\\\\n",
    "  --checkpointing_steps 200 \\\\\n",
    "  --beta_dpo 5000 \\\\\n",
    "  --output_dir=\"/local1/bryanzhou008/Dialect/multimodal-dialectal-bias/mitigation/baselines/diffusion_dpo/a_checkpoints/{exp_name}\" \n",
    "\"\"\".format(output_dir=output_folder, exp_name=exp_name, num_processes=num_processes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created at /local1/bryanzhou008/Dialect/multimodal-dialectal-bias/mitigation/baselines/diffusion_dpo/a_data/ine-dpo-basic-2-2-2-9\n",
      "Total metadata entries: 1188\n",
      "Training script created at /local1/bryanzhou008/Dialect/multimodal-dialectal-bias/mitigation/baselines/diffusion_dpo/a_data/ine-dpo-basic-2-2-2-9/run_training.sh\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Preparation and Script Generation\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create the output training directory (we'll place all processed images and metadata in a \"train\" subfolder)\n",
    "train_dir = os.path.join(output_folder, \"train\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "metadata = []\n",
    "\n",
    "# Read the CSV file and iterate over the rows (skip header)\n",
    "with open(csv_file, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    # For each row, use Dialect_Prompt as the folder for lose images, SAE_Prompt for win images.\n",
    "    for row_index, row in enumerate(reader):\n",
    "        dialect_prompt = row[\"Dialect_Prompt\"].strip()\n",
    "        sae_prompt = row[\"SAE_Prompt\"].strip()\n",
    "        \n",
    "        # Determine source directories for this row\n",
    "        lose_dir = os.path.join(input_images_folder, \"dialect_imgs\", dialect_prompt)\n",
    "        win_dir  = os.path.join(input_images_folder, \"sae_imgs\", sae_prompt)\n",
    "        \n",
    "        # For each prompt, take the first num_train_per_prompt images (assumed named \"0.jpg\", \"1.jpg\", etc.)\n",
    "        for i in range(num_train_per_prompt):\n",
    "            # Define source file paths.\n",
    "            win_src = os.path.join(win_dir, f\"{i}.jpg\")\n",
    "            \n",
    "            # For \"dpo\", also get lose image; for \"sft\", we only need the win image.\n",
    "            if method.lower() == \"dpo\":\n",
    "                lose_src = os.path.join(lose_dir, f\"{i}.jpg\")\n",
    "            else:\n",
    "                lose_src = None  # not used in sft\n",
    "            \n",
    "            # Check existence of the required files.\n",
    "            if not os.path.exists(win_src):\n",
    "                print(f\"Warning: Win image missing at {win_src}; skipping row {row_index}, image {i}.\")\n",
    "                continue\n",
    "            if method.lower() == \"dpo\" and not os.path.exists(lose_src):\n",
    "                print(f\"Warning: Lose image missing at {lose_src}; skipping row {row_index}, image {i}.\")\n",
    "                continue\n",
    "            \n",
    "            # Define destination filenames to avoid collisions across rows.\n",
    "            win_dest_name = f\"win_{row_index}_{i}.jpg\"\n",
    "            win_dest_path = os.path.join(train_dir, win_dest_name)\n",
    "            shutil.copy(win_src, win_dest_path)\n",
    "            \n",
    "            if method.lower() == \"dpo\":\n",
    "                lose_dest_name = f\"lose_{row_index}_{i}.jpg\"\n",
    "                lose_dest_path = os.path.join(train_dir, lose_dest_name)\n",
    "                shutil.copy(lose_src, lose_dest_path)\n",
    "            \n",
    "            prompt_text = dialect_prompt  # Use the Dialect_Prompt as caption.\n",
    "            \n",
    "            if method.lower() == \"dpo\":\n",
    "                # For dpo, create two metadata entries: one for win and one for lose.\n",
    "                win_entry = {\n",
    "                    \"file_name\": win_dest_name,\n",
    "                    \"jpg_0\": win_dest_name,\n",
    "                    \"jpg_1\": lose_dest_name,\n",
    "                    \"label_0\": 1,\n",
    "                    \"caption\": prompt_text\n",
    "                }\n",
    "                lose_entry = {\n",
    "                    \"file_name\": lose_dest_name,\n",
    "                    \"jpg_0\": win_dest_name,\n",
    "                    \"jpg_1\": lose_dest_name,\n",
    "                    \"label_0\": 1,\n",
    "                    \"caption\": prompt_text\n",
    "                }\n",
    "                metadata.extend([win_entry, lose_entry])\n",
    "            else:  # sft: use only win images.\n",
    "                win_entry = {\n",
    "                    \"file_name\": win_dest_name,\n",
    "                    \"jpg_0\": win_dest_name,\n",
    "                    \"caption\": prompt_text\n",
    "                }\n",
    "                metadata.append(win_entry)\n",
    "\n",
    "# Write the metadata.jsonl file in the train directory.\n",
    "metadata_path = os.path.join(train_dir, \"metadata.jsonl\")\n",
    "with open(metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in metadata:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"Dataset created at {output_folder}\")\n",
    "print(f\"Total metadata entries: {len(metadata)}\")\n",
    "\n",
    "# Create the training shell script using the script_command from Cell 1.\n",
    "script_path = os.path.join(output_folder, \"run_training.sh\")\n",
    "with open(script_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(script_command)\n",
    "    \n",
    "# Make the script executable.\n",
    "os.chmod(script_path, 0o755)\n",
    "print(f\"Training script created at {script_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
